---
title: "Assignment3"
author: "Kexin Wu"
date: "24/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment 3 for Stastistical Computing and Empirical Methods

# 1 Random experiments, events and sample spaces

• What is the random experiment in your example?  Throwing a coin

• What are the possible outcomes in your example?  Head up and tail up

• What are the events in your example? 

• What is the sample space in your example? {head up, tail up}

# 2 Tidy data and iteration

# 2.1 Missing data and iteration

 In this task we investigate the effect of missing data and imputation on plots.The following function performs imputation by mean. What library do we need to load to run this function?
```{r}
library(tidyverse)
impute_by_mean <- function(x){
   mu <- mean(x, na.rm = 1) # first compute the mean of x
   impute_f <- function(z){ # coordinate-wise imputation
     if(is.na(z)){
       return(mu) # if z is na replace with mean
       }else{
         return(z) # otherwise leave in place
         }
   }
   return(map_dbl(x, impute_f)) # apply the map function to impute across vector
 }
v <- c(1, 2, NA, 4)
impute_by_mean(v)
```

 Create a function called impute_by_median which imputes missing values based on the median of the sample, rather than the mean.
```{r}
impute_by_median <- function(x){
  mu <- median(x, na.rm = 1) # first compute the median of x
  impute_f <- function(z){ # coordinate-wise imputation
    if(is.na(z)){
      return(mu) # if z is na replace with median
    }else{
      return(z) # otherwise leave in place
    }
  }
  return(map_dbl(x, impute_f))
}
v <- c(1, 2, NA, 4)
impute_by_median(v)
```

 Next generate a data frame with two variables x and y. For our first variable x we have a sequence (x1,x2,...,xn) where x1 = 0, xn = 10 and for each i = 1,...,n − 1, xi+1 = xi + 0.1. For our second variable y we set yi = 5 × xi + 1 for i = 1, . . . , n. Generate data of this form and place within a data frame called df_xy.
```{r}
x <- seq(0, 10, +0.1)
y <- 5 * x + 1
df_xy <- data.frame(x, y)
df_xy %>% head(5)
```

The map2() function is similar to the map() function but iterates over two variables in parallel rather than one. You can learn more here https://purrr.tidyverse.org/reference/map2.html. The following simple example shows you how map2_dbl() can be combined with the mutate() function.
```{r}
library(dplyr)
library(purrr)
df_xy %>%
  mutate(z = map2_dbl(x, y, ~.x+.y)) %>%
  head(5)
```

 We will now use map2_dbl() to generate a new data frame with missing data.

 First create a function sometimes_missing with two variables index and value. The function should return
NA if index is divisible by 5 and returns value otherwise. 
```{r}
sometimes_missing <- function(i, v){
  if(i %% 5 == 0){
    return(NA)
  }else{
    return(v)
  }
}
sometimes_missing(14, 25)
sometimes_missing(15, 25)
```

 Next generate a new data frame called df_xy_missing with two variables x and y, but some missing data.   
 For the first variable x we have a sequence (x1 , · · · , xn ), which is precisely the same as with df_xy. For the second variable y we have a sequence (y ̃1,··· ,y ̃n) where y ̃i = NA if i is divisible by 5 and y ̃i = yi for i not divisible by 5. To generate the dataframe d_xy_missing you may want to make use of the functions row_number(), map2_dbl(), mutate() as well as sometimes_missing().
```{r}
df_xy_missing <- df_xy %>%
  mutate(y = map2_dbl(row_number(), y, sometimes_missing))
df_xy_missing %>%
  head(10)
```

 Create a new data frame df_xy_imputed with two variables x and y. For the first variable x we have a sequence (x1 , · · · , xn ), which is precisely the same as with df_xy. For the second variable y we have a sequence (y1′ , · · · , yn′ ) which is formed from (y ̃1 , · · · , y ̃n ) by imputing any missing values with the median. To generate df_xy_imputed from “‘df_xy_missing by applying a combination of the functions mutate and impute_by_median().
```{r}
df_xy_imputed <- df_xy_missing %>%
  mutate(y = impute_by_median(y))
```

 Combine the dataframes df_xy, df_xy_missing and df_xy_impute within a single dataframe called df_combined, along with an additional column indicating the source of the data.
```{r}
df_xy <- df_xy %>%
  mutate(source = "original")
df_xy_missing <- df_xy_missing %>%
  mutate(source = "corrupter")
df_xy_imputed <- df_xy_imputed %>%
  mutate(source = "imputed")
df_combined <- rbind(df_xy, df_xy_missing, df_xy_imputed)
```
 Plot the original data, the corrupted data and the imputed data together together with a trend line for each sample.
```{r}
library(ggplot2)
ggplot(df_combined, aes(x = x, y = y, color = source)) + geom_point() + 
  facet_wrap(~source) + geom_smooth(method = "lm")
```

# 2.2 Tidying data with pivot functions

 In this task you will read in data from a spreadsheet and apply some data wrangling tasks to tidy that data.
 
 First download the excel spreadsheet entitled “HockeyLeague.xlsx”. The excel file contains two spread- sheets - one with the wins for each team and one with the losses for each team. To read this spreadsheet into R we shall make use of the readxl library. You may need to install the library

 The following code shows how to read in a sheet within an excel file as a data frame. You will need to edit the folder_path variable to be the directory which contains your copy of the spreadsheet.
```{r}
library(readxl) # load the readxl library
folder_path <- "/Users/wukexin/Desktop/SCEM/assignments/" 
# set this to the name o the directory containing  "HockeyLeague.xlsx"
file_name <- "HockeyLeague.xlsx" # set the file name
file_path <- paste(folder_path, file_name, sep = "") # create the file_path
wins_data_frame <- read_excel(file_path, sheet = "Wins") # read of a sheet from an xl file
```
 Inspect the first 3 rows of the first five columns:
```{r}
wins_data_frame %>%
  select(1 : 5) %>%
  head(3)
```
 A cell value of the form “a of b” means that a games were won out of a total of b for that season. For example, the element for the “Ducks” row of the “1990” column is “30 of 50” meaning that 30 out of 50 games were won that season.
 
 Now apply your data wrangling skills to transform the “wins_data_frame” data frame object into a data frame called “wins_tidy” which contains the same information but has just four columns entitled “Team”, “Year”, “Wins”, “Total”. The “Team” column should contain the team name, the “Year” column should contain the year, the “Wins” column should contain the number of wins for that season and the “Total” column the total number of games for that season. The first column should be of character type and the remaining columns should be of integer type. You can do this by combining the following functions: rename(), pivot_longer(), mutate() and separate().
```{r}
wins_tidy <- wins_data_frame %>%
  rename('Team' = ...1) %>%
  pivot_longer(!Team, names_to = "year") %>%
  separate(value, into = c("Wins", "Total"), sep ="of", convert = TRUE)
wins_tidy %>% dim()
wins_tidy %>% head(5)
```

 Apply a similar procedure to read the data from this sheet and transform that data into a dataframe called “losses_tidy” with four columns: “Team”, “Year”, “Losses”, “Total” which are similar to thos in the “wins_tidy” data frame except for the “Losses” column gives the number of losses for a given season and team, rather than the number of losses.
```{r}
w_l_narrow <- function(w_or_l){
  return(
    read_excel(file_path, sheet = w_or_l) %>%
      rename(Team = ...1) %>%
      pivot_longer(!Team, names_to = "Year", values_to = "val") %>%
      mutate(Year = as.integer(Year)) %>%
      separate(col = val, into = c(w_or_l, "Total"), sep = " of ", convert = TRUE)
  )
}
wins_tidy <- w_l_narrow(w_or_l = "Wins")
losses_tidy <- w_l_narrow(w_or_l = "Losses")
wins_tidy
losses_tidy
```

 Now combine your two data frames, “wins_tidy” and “losses_tidy”, into a single data frame entitled “hockey_df” which has 248 rows and 9 columns: A “Team” column which gives the name of the team as a character, the “Year” column which gives the season year, the “Wins” column which gives the number of wins for that team in the given year, the “Losses” column which gives the number of losses for that team in the given year and the “Draws” column which gives the number of draws for that team in the given year, the “Wins_rt” which gives the wins as a proportion of the total number of games (ie. Wins/Total) and similarly the “Losses_rt” and the “Draws_rt” which gives the losses and draws as a proportion of the total, respectively. To do this you can make use of the mutate() function. You may also want to utilise the across() function for a slightly neater solution.
```{r}
hocky_df <- inner_join(wins_tidy, losses_tidy) %>%
  mutate(Draws = Total - Wins - Losses) %>%
  mutate(across(starts_with(c("Wins", "Losses", "Draws")), ~.x/Total, .names = "{.col}_rt"))
hocky_df %>% head(5)
```
 
 To conclude this task generate a summary data frame which displays, for each team, the median win rate, the mean win rate, the median loss rate, the mean loss rate, the median draw rate and the mean draw rate. The number of rows in your summary should equal the number of teams. These should be sorted in descending order or median win rate. You may want to make use of the following functions: select(), group_by(), across(), arrange().
```{r}
hocky_df %>% 
  select(-Wins, -Draws, -Losses, -Total) %>%
  group_by(Team) %>%
  summarise(across(starts_with(c("Wins", "Losses", "Draws")), list(md = median, mn = mean),
                   .names = "{substring(.col, 1, 1)}_{.fn}")) %>%
  arrange(desc(W_md))
```

# 2.3 Most correlated variables(*)

 This data wrangling task is slightly more challenging. You may want to return to this task once you have completed the unstarred questions in sections 3 and 4 below.

 The objective is to investigate, for each numerical variable within a data set, which other numerical variables have the largest correlation (in absolute value).
 
 In lecture 6 we introduced the following function called “max_cor_var”. The function entitled “max_cor_var” takes as input a data frame “df” and a column name “col_name”. It then extracts the variable with name col_name and determines which other numerical variables within the data set have the highest correlation (in absolute value) with that variable. It then returns a data frame containing the name of the variable “var_name” and the corresponding correlation “cor”. Begin by making sure you understand the structure of the function.
```{r}
max_cor_var<-function(df,col_name){
# function to determine the variable with maximal correlation
v_col<-df%>%select(all_of(col_name)) # extract variable based on col_name
  df_num<-df%>%
    select_if(is.numeric)%>%
    select(-all_of(col_name))
  # select all numeric variables excluding col_name
correlations<-unlist(map(df_num, function(x){cor(x,v_col,use="complete.obs")}))
  # compute correlations with all other numeric variables
max_abs_cor_var<-names(which(abs(correlations)==max(abs(correlations)))) # extract the variable name cor<-as.double(correlations[max_abs_cor_var])
# compute the correlation
  return(data.frame(var_name=max_abs_cor_var,cor=cor))
  # return dataframe
}
```

 Next generate a new function called “top_correlates_by_var” which takes input a data frame “df” and outputs a data frame with a single row. The column names of this output data frame should coincide with the names of the numerical columns within the input dataframe “df”. For each column name, the value should be equal to variable name corresponding to the numerical variable which has the highest level of correlation (in absolute value) to the variable with that column name, but is not equal to it.
```{r}
top_correlates_by_var<-function(df){
  cols_numeric<-df%>%
  select_if(is.numeric)%>%
  colnames()
  max_cor_vars<-map_chr(cols_numeric,~unlist(max_cor_var(df,.x)["var_name"]))
  max_cor_by_var_name<-data.frame(var_name=cols_numeric,max_cor_var=max_cor_vars)
  max_cor_by_var_name%>%
    pivot_wider(names_from=var_name,values_from=max_cor_var)
}
```
 You can test your function as follows. By using the Palmer penguins data set you should obtain the following output.
```{r}
library(palmerpenguins)
#penguins %>%
  #top_correlates_by_var()
```

# 3 Elementary set theory